{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGWj9AB43TPsYuzqZcfe1d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRw6L6v0ybiE","executionInfo":{"status":"ok","timestamp":1744558683524,"user_tz":240,"elapsed":122790,"user":{"displayName":"Sai Teja Bandaru","userId":"00987261360328578268"}},"outputId":"cd8a5df3-12a5-4e15-982e-77867703a174"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ“… Date: 2025-03-30\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-03-31\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-01\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-02\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-03\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-04\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-05\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-06\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-07\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-08\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-09\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-10\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-11\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","ğŸ“… Date: 2025-04-12\n","ğŸ” Fetching from fox-news...\n","ğŸ” Fetching from cnn...\n","ğŸ” Fetching from abc-news...\n","ğŸ” Fetching from techcrunch...\n","\n","âœ… Done! Total Articles: 3356\n","ğŸ“ File saved as: all_news_mar30_to_apr12_combined.xlsx\n"]}],"source":["import requests\n","import pandas as pd\n","import datetime\n","import time\n","\n","# ğŸ” NewsAPI Key\n","API_KEY = \"18f06556ed6e4b90b1c6c90ce48b6b0d\"  # Replace with your key if needed\n","# 18f06556ed6e4b90b1c6c90ce48b6b0d\n","\n","# ğŸ“° News sources\n","news_sources = [\"fox-news\", \"cnn\", \"abc-news\", \"techcrunch\"]\n","\n","# ğŸ“… Date range: March 30 to April 12, 2025\n","start_date = datetime.date(2025, 3, 30)\n","end_date = datetime.date(2025, 4, 12)\n","date_range = [start_date + datetime.timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n","\n","# ğŸ“¦ Storage for all articles\n","all_articles = []\n","\n","# ğŸ” Loop through each date and source\n","for date in date_range:\n","    date_str = date.strftime('%Y-%m-%d')\n","    print(f\"\\nğŸ“… Date: {date_str}\")\n","\n","    for source in news_sources:\n","        print(f\"ğŸ” Fetching from {source}...\")\n","\n","        url = (\n","            f\"https://newsapi.org/v2/everything?\"\n","            f\"sources={source}&from={date_str}&to={date_str}&pageSize=100&language=en&apiKey={API_KEY}\"\n","        )\n","\n","        try:\n","            response = requests.get(url)\n","            data = response.json()\n","\n","            if data[\"status\"] == \"ok\":\n","                for article in data[\"articles\"]:\n","                    all_articles.append({\n","                        \"source_id\": article[\"source\"].get(\"id\", \"N/A\"),\n","                        \"source_name\": article[\"source\"][\"name\"],\n","                        \"author\": article.get(\"author\", \"N/A\"),\n","                        \"title\": article.get(\"title\", \"N/A\"),\n","                        \"description\": article.get(\"description\", \"N/A\"),\n","                        \"url\": article.get(\"url\", \"N/A\"),\n","                        \"urlToImage\": article.get(\"urlToImage\", \"N/A\"),\n","                        \"publishedAt\": article.get(\"publishedAt\", \"N/A\"),\n","                        \"content\": article.get(\"content\", \"N/A\"),\n","\n","                    })\n","            else:\n","                print(f\"âŒ API Error from {source} on {date_str}: {data}\")\n","        except Exception as e:\n","            print(f\"âš ï¸ Exception from {source} on {date_str}: {e}\")\n","\n","        time.sleep(1)  # Avoid hitting rate limit\n","\n","# ğŸ’¾ Save all data to a single Excel sheet\n","df_all = pd.DataFrame(all_articles)\n","output_path = \"all_news_mar30_to_apr12_combined.xlsx\"\n","df_all.to_excel(output_path, index=False)\n","\n","print(f\"\\nâœ… Done! Total Articles: {len(df_all)}\")\n","print(f\"ğŸ“ File saved as: {output_path}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"hJD7U4xRypYY"},"execution_count":null,"outputs":[]}]}